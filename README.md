# Challenge-Telecom-X---Parte-2
Challenge Telecomx 2 - Creaci√≥n de un modelo de predicci√≥n (Evasoi√≥n de Clientes - churn)

## √çndice üìã

1. Descripci√≥n del proyecto.
2. Acceso al proyecto
3. Etapas del proyecto.
4. Descripci√≥n de los datos
5. Resultados y conclusiones
6. Tecnolog√≠as utilizadas.
7. Agradecimientos.
8. Desarrollador del proyecto.

## 1. Descripci√≥n del proyecto üìö

* Se desarrollaron varios modelos supervisados de Machine Learning para identificar clientes propensos a cancelar el servicio en una empresa de telecomunicaciones, el modelo con mejor desempe√±o a trav√©s de m√©tricas de evaluaci√≥n espec√≠ficas sera le ganador.
* Los datos se ajustaron a los requerimientos de cada algoritmo, teniendo en cuanta la sensibilidad  y la multicolinealidad entre variables.
* Optimizaci√≥n de hiperpar√°metros (dentro cada conjunto de datos), seleccionando el mejor modelo por cada conjunto de datos para luego compararlos entre s√≠. En la selecci√≥n final prioriz√≥ la m√©trica **Recall**, a fin de minimizar los falsos negativos (clientes que abandonan y no son detectados), sin comprometer la **Precisi√≥n**.
* Finalmente, en un entorno de simulaci√≥n productiva con datos sint√©ticos se valido la operaci√≥n del modelo.

## Acceso al proyecto üìÇ

Para obtener acceso el proyecto hacer lo siguiente:

1. Puedes descargarlo directamente desde el repositorio en GitHub en el siguiente enlace:
   <p><a href="https://github.com/jalonzoh/Challenge-Telecom-X---Parte-2">https://github.com/jalonzoh/Challenge-Telecom-X---Parte-2</p>

Descargar un archivo comprimido `.zip`.


## 3. Etapas del proyecto üìù

1. Descripci√≥n del proyecto
2. Importaci√≥n de librer√≠as y configuraciones
   - Importaci√≥n de librerias
   - Paths
   - Configuraciones
   - Funciones
3. Preprocesamiento de datos
   - Encoding de variables categ√≥ricas
   - Normalizacion de datos
   - Correlacion entre variables
   - An√°lisis de multicolinealidad
   - An√°lisis dirigido
4. Modelado de datos
   - Train Test split
   - Escalado de variables num√©ricas
   - Balance del dataset
   - Baseline Model - Decision Tree Classifier
   - Random Forest Classifier
   - Logistic Regression
   - K-Nearest Neighbors
   - XGBoost Classifier
   - Support Vector Machine
6. Evaluaci√≥n Best Models
   - M√©tricas Generales
   - Subajuste (Underfitting) y Sobreajuste (Overfitting)
   - Matrices de confusi√≥n
   - Importancias y Coeficientes
7. Champion Model
8. Pipeline de prueba en entorno productivo
   - Generaci√≥n de datos artificiales
   - Pipeline de prueba

## 4. Descripci√≥n de los datos üìä

En la etapa anterior, se realiz√≥ exploraci√≥n y limpieza de los datos, obteniendo dos conjuntos de datos:
* <a href="ttps://raw.githubusercontent.com/jalonzoh/Challenge-Telecom-X---Parte-2/refs/heads/main/TelecomX_dataLimpio.json">TelecomX_dataLimpio.json</a>
* <a href="https://raw.githubusercontent.com/jalonzoh/Challenge-Telecom-X---Parte-2/refs/heads/main/no_clientes_importantes.json">no_clientes_importantes.json</a>

Ambos archivos se unieron en uno solo dando **7152 registros**. El archivo **no_clientes_importantes.json** contiene clientes que abandonaron la empresa en la etapa anterior, se incluyen en este proyecto para tener un escenario real del comportamiento de los clientes.

### Variables

| Variable           | Tipo       | Descripci√≥n breve                         | Valores originales                             | Preprocesado          |
| ------------------ | ---------- | ----------------------------------------- | ---------------------------------------------- | --------------------- |
| `customerID`       | Categ√≥rica | Identificador √∫nico del cliente           | String                                         | -                     |
| `Gender`           | Categ√≥rica | G√©nero del cliente                        | `'Male'`, `'Female'`                           | One-hot-encoding      |
| `SeniorCitizen`    | Categ√≥rica | Indica si el cliente es mayor de 65 a√±os  | `0`, `1`                                       | One-hot-encoding      |
| `Partner`          | Categ√≥rica | Si el cliente tiene pareja                | `'Yes'`, `'No'`                                | One-hot-encoding      |
| `Dependents`       | Categ√≥rica | Si el cliente tiene personas a cargo      | `'Yes'`, `'No'`                                | One-hot-encoding      |
| `PhoneService`     | Categ√≥rica | Si tiene servicio telef√≥nico              | `'Yes'`, `'No'`                                | One-hot-encoding      |
| `MultipleLines`    | Categ√≥rica | Si tiene m√∫ltiples l√≠neas telef√≥nicas     | `'Yes'`, `'No'`,                               | One-hot-encoding      |
| `InternetService`  | Categ√≥rica | Tipo de conexi√≥n a internet               | `'DSL'`, `'Fiber optic'`, `'No'`               | One-hot-encoding      |
| `OnlineSecurity`   | Categ√≥rica | Seguridad en l√≠nea                        | `'Yes'`, `'No'`,                               | One-hot-encoding      |
| `OnlineBackup`     | Categ√≥rica | Respaldo en l√≠nea                         | `'Yes'`, `'No'`,                               | One-hot-encoding      |
| `DeviceProtection` | Categ√≥rica | Protecci√≥n de dispositivo                 | `'Yes'`, `'No'`,                               | One-hot-encoding      |
| `TechSupport`      | Categ√≥rica | Soporte t√©cnico                           | `'Yes'`, `'No'`,                               | One-hot-encoding      |
| `StreamingTV`      | Categ√≥rica | TV en streaming                           | `'Yes'`, `'No'`,                               | One-hot-encoding      |
| `StreamingMovies`  | Categ√≥rica | Pel√≠culas en streaming                    | `'Yes'`, `'No'`,                               | One-hot-encoding      |
| `Contract`         | Categ√≥rica | Tipo de contrato                          | `'Month-to-month'`, `'One year'`, `'Two year'` | One-hot-encoding      |
| `PaperlessBilling` | Categ√≥rica | Si el cliente usa facturaci√≥n electr√≥nica | `'Yes'`, `'No'`                                | One-hot-encoding      |
| `PaymentMethod`    | Categ√≥rica | M√©todo de pago                            | 4 categor√≠as                                   | One-hot-encoding      |
| `Tenure`           | Num√©rica   | Antig√ºedad en meses                       | int, `0` a `72`                                | Igual/Escalado        |
| `ChargesMonthly`   | Num√©rica   | Costo mensual del servicio                | float                                          | Igual/Escalado        |
| `ChargesTotal`     | Num√©rica   | Costo total acumulado del cliente         | float                                          | Igual/Escalado        |
| `ChargesDaily`     | Num√©rica   | Estimaci√≥n diaria del costo del cliente   | float (`Charges.Monthly/30`)                   | Descartada            |
| `Churn`            | Categ√≥rica | Si el cliente abandon√≥ la empresa         | `'Yes'`, `'No'`                                | Label Encoding        |

### Balance de clases

Al ver un desbalance en la variable de respuesta (`Churn`), se hizo una reducci√≥n del Dataset utilizando `NearMiss Version 3`.
Se redujo la clase mayoritaria para que los modelos contubieran datos reales y no generar sesgos. 

Esta reducci√≥n dio como resultado un conjunto de datos con **3362 registros** para el entrenamiento, y conservando la distribuci√≥n original de los datos para la evaluaci√≥n de modelos, con un total de **1073 registros**, de lo cual **72.3%** son etiquetados como `Churn = 0` (clase mayoritaria) y **27.7%** etiquetados como `Churn = 1` (clase minoritaria).

Para la simulaci√≥n del pipeline en productivo, se generaro datos artificiales utilizando la t√©cnica `SMOTENC`.

### Codificaci√≥n y reescalado de datos

* Modelos basados en √°rboles: `Random Forest Classifier` y `XGBoost Classifier`
  - Codificaci√≥n `One-hot`, descartando una variable cuando esta era de naturaleza binaria (dos categor√≠as) a trav√©s del par√°metro `drop='if_binary'`.
  - Variables num√©ricas: `Tenure`, `ChargesMonthly` y `ChargesTotal` no fueron escaladas ya que estos modelos no se ven afectados por la escala de los datos debido a su naturaleza basada en particiones y √°rboles.

* Modelos lineales: `Logistic Regression` y `Support Vector Machine (kernel = 'linear')`
  - Codificaci√≥n `One-hot` para variables categ√≥ricas con el par√°metro `drop='first'` descartando la primera categor√≠a de cada variable para evitar introducir multicolinealidad al modelo.
  - Variables num√©ricas: escaladas utilizando `Robust Scaler` debido a la presencia de valores at√≠picos, el cual utiliza la mediana y el rango intercuart√≠lico (IQR) para escalar los datos (lo cual lo hace resistente a outliers), debido a la sensibilidad de dichos modelos a la escala de los datos.
  - Dataset: `X_linear`

* Modelos basados en distancia: `K-Nearest Neighbors Classifier`
  - Codificaci√≥n `One-hot` con el par√°metro `drop='if_binary'`, ya que este tipo de modelos se beneficia de mayor cantidad de variables al calcular la distancia entre observaciones.
  - Variables num√©ricas escaladas con `Robust Scaler`, ya que el modelo es sensible a la escala de los datos.
  - Dataset: `X_scaled`
 
* La variable respuesta (Churn) fue codificada utilizando `Label Encoder`, transformando:
  - `'Yes'` -> `1`
  - `'No'` -> `0`

<br><br>
## 5. Resultados y conclusiones ‚úçÔ∏è

### Modelos

Al evaluar los modelos de cada familia para seleccionar un modelo campe√≥n (**Champion Model**), se obtubo los siguientes resultados de los modelos:

| Modelo                       | Dataset                      | Accuracy | Precision | Recall | F1-score | AUC    | Umbral |
|------------------------------|------------------------------|----------|-----------|--------|----------|--------|--------|
| Best Random Forest           | X                            | 0.7698   | 0.5654    | 0.7273 | 0.6362   | 0.8326 | 0.5    |
| Best Logistic Regression     | X_linear[selected_features]  | 0.7633   | 0.5657    | 0.6229 | 0.5929   | 0.8137 | 0.5    |
| Best K-Nearest Neighbors     | X_linear                     | 0.7251   | 0.5027    | 0.6364 | 0.5617   | 0.7513 | 0.5    |
| Best XGBoost Classifier      | X                            | 0.7568   | 0.5464    | 0.7138 | 0.6190   | 0.8188 | 0.5    |
| Best Support Vector Machine  | X_linear                     | 0.7540   | 0.5563    | 0.5488 | 0.5525   | 0.8073 | 0.5    |

Se busc√≥ llevar la m√©trica **Recall** a un valor m√≠nimo de 0.85 al modificar el umbral de decisi√≥n del modelo:

| Modelo                       | Dataset                      | Accuracy | Precision | Recall | F1-score | AUC    | Umbral |
|------------------------------|------------------------------|----------|-----------|--------|----------|--------|--------|
| Best Random Forest           | X                            | 0.7148   | 0.4914    | 0.8620 | 0.6259   | 0.8326 | 0.39   |
| Best Logistic Regression     | X_linear[selected_features]  | 0.6747   | 0.4539    | 0.8620 | 0.5947   | 0.8137 | 0.39   |
| Best XGBoost Classifier      | X                            | 0.6925   | 0.4695    | 0.8552 | 0.6062   | 0.8188 | 0.38   |
| Best Support Vector Machine  | X_linear                     | 0.6785   | 0.4571    | 0.8620 | 0.5974   | 0.8073 | 0.38   |

Para los resultados de las m√©tricas obtenidas, se seleccion√≥ el modelo `Best Random Forest` como **Champion Model** para implementaci√≥n en entorno productivo, esto debido a su capacidad de generalizaci√≥n.

A pesar de mostrar cierto sobreajuste a los datos de entrenamiento, como puede verse en las tablas a continuaci√≥n, `Best Random Forest` se mantiene como el mejor generalizador.


| Model	                       | Recall Train	 | Recall Test	     | Variaci√≥n   |
|-------------------------------|----------------|------------------|-------------|
| Best Random Forest	           | 0.8769	       | 0.7273	        | -14.96%     |
| Best Logistic Regression	     | 0.6383	       | 0.6229	        | -1.54%      | 
| Best XGBoost Classifier	     | 0.7555	       | 0.7138	        | -4.17%      | 
| Best Support Vector Machine   | 0.5996	       | 0.5488	        | -5.08%      | 

| Model	                       | F1-score Train	 | F1-score Test	     | Variaci√≥n   |
|-------------------------------|-------------------|---------------------|-------------|
| Best Random Forest	           | 0.8673	          | 0.6362              | -23.11%     |
| Best Logistic Regression	     | 0.6301	          | 0.5929	           | -3.72%      |
| Best XGBoost Classifier	     | 0.7591	          | 0.6190	           | -14.01%     |
| Best Support Vector Machine	  | 0.6126	          | 0.5525	           | -6.01%      |

### Pipeline de prueba

Se desarroll√≥ la simulaci√≥n de un pipeline para la implementaci√≥n del modelo en entorno productivo, utilizando datos sint√©ticos generados con la t√©cnica `SMOTENC`.
El mismo, recibe un archivo JSON  con datos sin ninguna transformaci√≥n para producir predicciones.
Cuenta con dos modos de utilizaci√≥n:

* `mode='production'`: que devuelve un archivo JSON con `CustomerID`, `Probabilidad Churn` y `Churn` *(Etiqueta: si Probabilidad Churn >= 0.39, Churn = 1, si Probabilidad Churn < 0.39, Churn = 0)*
* `mode='monitor'`: devuelve un archivo JSON con un campo con fecha y hora de ejecuci√≥n del monitoreo (`Model`), sus m√©tricas `Accuracy`, `Precision`, `Recall` y `F1-score`, para umbral de decisi√≥n por defecto y umbral de decisi√≥n modificado, y tiempo de predicci√≥n.

Dicho pipeline realiza las transformaciones necesarias sobre los datos crudos utilizando los artefactos creados a lo largo del proyecto.

Todo esto permiti√≥ construir un modelo predictivo s√≥lido y su aplicabilidad real en entornos simulados.

## 6. Tecnolog√≠as utilizadas üõ†Ô∏è

* `Python-3.11.7`
* `Numpy-1.26.4`
* `pandas-2.2.2`
* `matplotlib-3.10.0`
* `seaborn-0.13.2`
* `scikit--learn-1.5.2`
* `imbalanced--learn-1.5.2`
* `xgboost-2.1.3`
* `Google Colab`
* `Git and GitHub`

## 7. Agradecimientos ü§ù

A Oracle y Alura LATAM 

## 8. Desarrollador üë∑

**| Jhon Alonzo | Data Scientist Junior |**
